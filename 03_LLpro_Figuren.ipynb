{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Figurenhäufigkeit in den Werken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('llpro_output/DEU073_Schicksale_einer_Seele.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU066_Der_Stechlin.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU007_Die_Mappe_meines_Urgroßvaters.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU039_Problematische_Naturen_Erste_Abtheilung.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU045_Witiko.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU096_Der_Golem.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU011_Soll_und_Haben.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU005_Der_Sonnenwirt.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU059_Irrungen_Wirrungen.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU079_Die_Aufzeichnungen_des_Malte_Laurids_Brigge.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU030_Die_verlorene_Handschrift.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU094_Der_Weg_ins_Freie.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU013_Barfüßele.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU061_Größenwahn_ELTeC_ausgabe.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU072_Im_alten_Eisen.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU097_Wellen.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU038_Der_Hungerpastor.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU032_Jürg_Jenatsch.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU025_Der_Amerika_Müde.txt.tsv'),\n",
       " PosixPath('llpro_output/DEU076_Caspar_Hauser.txt.tsv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(Path('llpro_output').glob('*'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>text</th>\n",
       "      <th>orig</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>is_para_start</th>\n",
       "      <th>is_section_start</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>lemma</th>\n",
       "      <th>morph</th>\n",
       "      <th>dep</th>\n",
       "      <th>head</th>\n",
       "      <th>speech</th>\n",
       "      <th>entity</th>\n",
       "      <th>character</th>\n",
       "      <th>coref_clusters</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>scene_label</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Im</td>\n",
       "      <td>Im</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADP</td>\n",
       "      <td>APPRART</td>\n",
       "      <td>in</td>\n",
       "      <td>AdpType=Prep|Case=Dat|Gender=Masc|Number=Sing|...</td>\n",
       "      <td>pp</td>\n",
       "      <td>12</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonscene</td>\n",
       "      <td>0</td>\n",
       "      <td>stative_event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Norden</td>\n",
       "      <td>Norden</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Norden</td>\n",
       "      <td>Case=Dat|Gender=Masc|Number=Sing</td>\n",
       "      <td>pn</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonscene</td>\n",
       "      <td>0</td>\n",
       "      <td>stative_event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>der</td>\n",
       "      <td>der</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>der</td>\n",
       "      <td>Case=Gen|Gender=Fem|Number=Sing|PronType=Art</td>\n",
       "      <td>det</td>\n",
       "      <td>3</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonscene</td>\n",
       "      <td>0</td>\n",
       "      <td>stative_event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Grafschaft</td>\n",
       "      <td>Grafschaft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Grafschaft</td>\n",
       "      <td>Case=Gen|Gender=Fem|Number=Sing</td>\n",
       "      <td>gmod</td>\n",
       "      <td>1</td>\n",
       "      <td>_</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonscene</td>\n",
       "      <td>0</td>\n",
       "      <td>stative_event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ruppin</td>\n",
       "      <td>Ruppin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>Ruppin</td>\n",
       "      <td>Case=Nom|Gender=*|Number=Sing</td>\n",
       "      <td>app</td>\n",
       "      <td>3</td>\n",
       "      <td>_</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonscene</td>\n",
       "      <td>0</td>\n",
       "      <td>stative_event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i        text        orig  is_sent_start  is_para_start  is_section_start  \\\n",
       "0  0          Im          Im              1              1                 1   \n",
       "1  1      Norden      Norden              0              0                 0   \n",
       "2  2         der         der              0              0                 0   \n",
       "3  3  Grafschaft  Grafschaft              0              0                 0   \n",
       "4  4      Ruppin      Ruppin              0              0                 0   \n",
       "\n",
       "     pos      tag       lemma  \\\n",
       "0    ADP  APPRART          in   \n",
       "1   NOUN       NN      Norden   \n",
       "2    DET      ART         der   \n",
       "3   NOUN       NN  Grafschaft   \n",
       "4  PROPN       NE      Ruppin   \n",
       "\n",
       "                                               morph   dep  head speech  \\\n",
       "0  AdpType=Prep|Case=Dat|Gender=Masc|Number=Sing|...    pp    12      _   \n",
       "1                   Case=Dat|Gender=Masc|Number=Sing    pn     0      _   \n",
       "2       Case=Gen|Gender=Fem|Number=Sing|PronType=Art   det     3      _   \n",
       "3                    Case=Gen|Gender=Fem|Number=Sing  gmod     1      _   \n",
       "4                      Case=Nom|Gender=*|Number=Sing   app     3      _   \n",
       "\n",
       "  entity character coref_clusters  scene_id scene_label event_id  \\\n",
       "0      O         O              _         0    Nonscene        0   \n",
       "1      O         O              0         0    Nonscene        0   \n",
       "2      O         O              _         0    Nonscene        0   \n",
       "3      O         O              _         0    Nonscene        0   \n",
       "4  B-LOC         O              _         0    Nonscene        0   \n",
       "\n",
       "     event_label  \n",
       "0  stative_event  \n",
       "1  stative_event  \n",
       "2  stative_event  \n",
       "3  stative_event  \n",
       "4  stative_event  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = files[1]\n",
    "\n",
    "annotated = pandas.read_csv(text, sep='\\t')\n",
    "annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_character_freq(annotated):\n",
    "    character_mentions = []\n",
    "\n",
    "    cur_character = []\n",
    "    for id, row in tqdm(annotated.iterrows(), total=len(annotated)):\n",
    "        if row['character'] == 'B-PER':\n",
    "            if len(cur_character) > 0:\n",
    "                character_mentions.append(' '.join(annotated.loc[cur_character, 'text']))\n",
    "            cur_character = [id]\n",
    "        if row['character'] == 'I-PER':\n",
    "            cur_character.append(id)\n",
    "\n",
    "    char_counter = collections.Counter()\n",
    "    char_counter.update([character_str for character_str, ids in character_mentions])\n",
    "\n",
    "    return pandas.DataFrame(char_counter.most_common(), columns=['mention', 'freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU073_Schicksale_einer_Seele.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104398/104398 [00:13<00:00, 7821.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU066_Der_Stechlin.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154597/154597 [00:20<00:00, 7595.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU007_Die_Mappe_meines_Urgroßvaters.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82269/82269 [00:06<00:00, 13508.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU039_Problematische_Naturen_Erste_Abtheilung.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225288/225288 [00:17<00:00, 12907.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU045_Witiko.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338070/338070 [00:30<00:00, 10986.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU096_Der_Golem.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90852/90852 [00:05<00:00, 15655.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU011_Soll_und_Haben.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 344302/344302 [00:26<00:00, 13181.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU005_Der_Sonnenwirt.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215012/215012 [00:15<00:00, 13772.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU059_Irrungen_Wirrungen.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63354/63354 [00:04<00:00, 13412.87it/s]\n",
      "  0%|          | 0/70472 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU079_Die_Aufzeichnungen_des_Malte_Laurids_Brigge.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70472/70472 [00:04<00:00, 15663.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU030_Die_verlorene_Handschrift.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307383/307383 [00:26<00:00, 11808.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU094_Der_Weg_ins_Freie.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144741/144741 [00:11<00:00, 12707.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU013_Barfüßele.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74804/74804 [00:05<00:00, 12932.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU061_Größenwahn_ELTeC_ausgabe.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 293243/293243 [00:22<00:00, 12874.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU072_Im_alten_Eisen.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64387/64387 [00:04<00:00, 13019.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU097_Wellen.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54751/54751 [00:04<00:00, 11685.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU038_Der_Hungerpastor.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166061/166061 [00:14<00:00, 11826.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU032_Jürg_Jenatsch.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83840/83840 [00:06<00:00, 13584.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU025_Der_Amerika_Müde.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197276/197276 [00:13<00:00, 14124.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llpro_output/DEU076_Caspar_Hauser.txt.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156609/156609 [00:13<00:00, 11220.56it/s]\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for text in files:\n",
    "    print(text)\n",
    "    annotated = pandas.read_csv(text, sep='\\t')\n",
    "    freqs = get_character_freq(annotated)\n",
    "\n",
    "    freqs = freqs[:100] # 100 häufigsten Figuren\n",
    "    freqs['filename'] = text.name\n",
    "    output.append(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pandas.concat(output).to_csv('figurenhäufigkeit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Figurenhäufigkeit/-reihenfolge in den Zusammenfassungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f275321c5654dff9e260855b3d5e36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3332b9a253f645de9e636d9c97e890ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7047dcc4ea4943a90e41b0bd385ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c807b644087d4892ac5cd2c020f599f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:17:48,419 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, B-PER, E-PER, S-LOC, B-MISC, I-MISC, E-MISC, S-PER, B-ORG, E-ORG, S-ORG, I-ORG, B-LOC, E-LOC, S-MISC, I-PER, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "character_tagger = SequenceTagger.load('flair/ner-german-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summaries = list(Path('kindler').glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from segtok.segmenter import split_single\n",
    "from flair.data import Sentence\n",
    "\n",
    "def get_character_freq_from_summary(summary_file):\n",
    "    summary = open(summary_file).read()\n",
    "    sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(summary)]\n",
    "    character_tagger.predict(sentences)\n",
    "    character_mentions = []\n",
    "    for sent in sentences:\n",
    "        for label in sent.labels:\n",
    "            if label.value == 'PER':\n",
    "                # immer nur Vornamen\n",
    "                character_mentions.append(label.data_point[0].text)\n",
    "                \n",
    "    freqs = pandas.DataFrame(collections.Counter(character_mentions).most_common(), columns=['mention', 'freq'])\n",
    "    freqs['filename'] = summary_file.name\n",
    "    freqs['occurence_order'] = freqs['mention'].apply(lambda x: character_mentions.index(x)+1)\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [12:32<00:00, 39.60s/it]\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for file in tqdm(summaries):\n",
    "    df = get_character_freq_from_summary(file)\n",
    "    output.append(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
